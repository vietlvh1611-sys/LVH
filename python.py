import streamlit as st
import pandas as pd
import google.generativeai as genai
from google.generativeai.types import generation_types
from google.api_core import exceptions

# --- Cáº¥u hÃ¬nh Trang Streamlit ---
st.set_page_config(
    page_title="App PhÃ¢n TÃ­ch BÃ¡o CÃ¡o TÃ i ChÃ­nh",
    layout="wide",
    initial_sidebar_state="collapsed"
)

st.title("á»¨ng dá»¥ng PhÃ¢n TÃ­ch BÃ¡o CÃ¡o TÃ i ChÃ­nh vá»›i Gemini AI ğŸ“Š")

# --- HÃ m tÃ­nh toÃ¡n chÃ­nh (Sá»­ dá»¥ng Caching Ä‘á»ƒ Tá»‘i Æ°u hiá»‡u suáº¥t) ---
@st.cache_data
def process_financial_data(df):
    """Thá»±c hiá»‡n cÃ¡c phÃ©p tÃ­nh TÄƒng trÆ°á»Ÿng vÃ  Tá»· trá»ng."""
    
    # Äáº£m báº£o cÃ¡c giÃ¡ trá»‹ lÃ  sá»‘ Ä‘á»ƒ tÃ­nh toÃ¡n
    numeric_cols = ['NÄƒm trÆ°á»›c', 'NÄƒm sau']
    for col in numeric_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
    
    # 1. TÃ­nh Tá»‘c Ä‘á»™ TÄƒng trÆ°á»Ÿng
    df['Tá»‘c Ä‘á»™ tÄƒng trÆ°á»Ÿng (%)'] = (
        (df['NÄƒm sau'] - df['NÄƒm trÆ°á»›c']) / df['NÄƒm trÆ°á»›c'].replace(0, 1e-9)
    ) * 100

    # 2. TÃ­nh Tá»· trá»ng theo Tá»•ng TÃ i sáº£n
    tong_tai_san_row = df[df['Chá»‰ tiÃªu'].str.contains('Tá»”NG Cá»˜NG TÃ€I Sáº¢N', case=False, na=False)]
    
    if tong_tai_san_row.empty:
        raise ValueError("KhÃ´ng tÃ¬m tháº¥y chá»‰ tiÃªu 'Tá»”NG Cá»˜NG TÃ€I Sáº¢N'. Vui lÃ²ng kiá»ƒm tra láº¡i file Excel.")

    tong_tai_san_N_1 = tong_tai_san_row['NÄƒm trÆ°á»›c'].iloc[0]
    tong_tai_san_N = tong_tai_san_row['NÄƒm sau'].iloc[0]

    divisor_N_1 = tong_tai_san_N_1 if tong_tai_san_N_1 != 0 else 1e-9
    divisor_N = tong_tai_san_N if tong_tai_san_N != 0 else 1e-9

    df['Tá»· trá»ng NÄƒm trÆ°á»›c (%)'] = (df['NÄƒm trÆ°á»›c'] / divisor_N_1) * 100
    df['Tá»· trá»ng NÄƒm sau (%)'] = (df['NÄƒm sau'] / divisor_N) * 100
    
    return df

# --- HÃ m gá»i API Gemini ---
def get_gemini_response(api_key, prompt, is_chat=False, chat_history=None):
    """
    Gá»­i yÃªu cáº§u Ä‘áº¿n Gemini API.
    - is_chat=False: Cho yÃªu cáº§u phÃ¢n tÃ­ch ban Ä‘áº§u (one-shot).
    - is_chat=True: Cho cuá»™c trÃ² chuyá»‡n, cáº§n cÃ³ chat_history.
    """
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash-latest')

        if is_chat:
            # Äá»‘i vá»›i chat, báº¯t Ä‘áº§u má»™t session vá»›i lá»‹ch sá»­
            chat = model.start_chat(history=chat_history)
            response = chat.send_message(prompt)
        else:
            # Äá»‘i vá»›i yÃªu cáº§u phÃ¢n tÃ­ch ban Ä‘áº§u
            response = model.generate_content(prompt)
        
        return response.text

    except exceptions.PermissionDenied:
        return "Lá»—i gá»i Gemini API: KhÃ³a API khÃ´ng há»£p lá»‡ hoáº·c Ä‘Ã£ háº¿t háº¡n. Vui lÃ²ng kiá»ƒm tra láº¡i."
    except generation_types.StopCandidateException as e:
        # Xá»­ lÃ½ trÆ°á»ng há»£p ná»™i dung bá»‹ cháº·n do an toÃ n
        return f"Pháº£n há»“i tá»« AI Ä‘Ã£ bá»‹ cháº·n. LÃ½ do: {e}. Vui lÃ²ng thá»­ láº¡i vá»›i cÃ¢u há»i khÃ¡c."
    except Exception as e:
        return f"ÄÃ£ xáº£y ra lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh khi káº¿t ná»‘i vá»›i Gemini: {e}"

# --- Giao diá»‡n chÃ­nh ---

# Chá»©c nÄƒng 1: Táº£i File
uploaded_file = st.file_uploader(
    "1. Táº£i file Excel BÃ¡o cÃ¡o TÃ i chÃ­nh (3 cá»™t: Chá»‰ tiÃªu | NÄƒm trÆ°á»›c | NÄƒm sau)",
    type=['xlsx', 'xls']
)

if uploaded_file is not None:
    try:
        df_raw = pd.read_excel(uploaded_file, header=None) # Äá»c khÃ´ng cÃ³ header
        
        # Tiá»n xá»­ lÃ½: Äáº£m báº£o chá»‰ cÃ³ 3 cá»™t vÃ  Ä‘áº·t tÃªn
        if df_raw.shape[1] < 3:
             st.error("Lá»—i: File Excel pháº£i cÃ³ Ã­t nháº¥t 3 cá»™t.")
        else:
            df_raw = df_raw.iloc[:, :3]
            df_raw.columns = ['Chá»‰ tiÃªu', 'NÄƒm trÆ°á»›c', 'NÄƒm sau']
            st.session_state.df_raw = df_raw.copy() # LÆ°u vÃ o session state
            
            # Xá»­ lÃ½ dá»¯ liá»‡u
            df_processed = process_financial_data(df_raw.copy())
            st.session_state.df_processed = df_processed # LÆ°u vÃ o session state

    except ValueError as ve:
        st.error(f"Lá»—i cáº¥u trÃºc dá»¯ liá»‡u: {ve}")
    except Exception as e:
        st.error(f"CÃ³ lá»—i xáº£y ra khi Ä‘á»c hoáº·c xá»­ lÃ½ file: {e}. Vui lÃ²ng kiá»ƒm tra Ä‘á»‹nh dáº¡ng file.")

if 'df_processed' in st.session_state:
    df_processed = st.session_state.df_processed
    
    # --- Chá»©c nÄƒng 2 & 3: Hiá»ƒn thá»‹ Káº¿t quáº£ ---
    st.subheader("2. Tá»‘c Ä‘á»™ TÄƒng trÆ°á»Ÿng & 3. Tá»· trá»ng CÆ¡ cáº¥u TÃ i sáº£n")
    st.dataframe(df_processed.style.format({
        'NÄƒm trÆ°á»›c': '{:,.0f}',
        'NÄƒm sau': '{:,.0f}',
        'Tá»‘c Ä‘á»™ tÄƒng trÆ°á»Ÿng (%)': '{:.2f}%',
        'Tá»· trá»ng NÄƒm trÆ°á»›c (%)': '{:.2f}%',
        'Tá»· trá»ng NÄƒm sau (%)': '{:.2f}%'
    }), use_container_width=True)
    
    # --- Chá»©c nÄƒng 4: TÃ­nh Chá»‰ sá»‘ TÃ i chÃ­nh ---
    st.subheader("4. CÃ¡c Chá»‰ sá»‘ TÃ i chÃ­nh CÆ¡ báº£n")
    try:
        tsnh_n = df_processed[df_processed['Chá»‰ tiÃªu'].str.contains('TÃ€I Sáº¢N NGáº®N Háº N', case=False, na=False)]['NÄƒm sau'].iloc[0]
        tsnh_n_1 = df_processed[df_processed['Chá»‰ tiÃªu'].str.contains('TÃ€I Sáº¢N NGáº®N Háº N', case=False, na=False)]['NÄƒm trÆ°á»›c'].iloc[0]
        no_ngan_han_N = df_processed[df_processed['Chá»‰ tiÃªu'].str.contains('Ná»¢ NGáº®N Háº N', case=False, na=False)]['NÄƒm sau'].iloc[0]
        no_ngan_han_N_1 = df_processed[df_processed['Chá»‰ tiÃªu'].str.contains('Ná»¢ NGáº®N Háº N', case=False, na=False)]['NÄƒm trÆ°á»›c'].iloc[0]

        thanh_toan_hien_hanh_N = tsnh_n / no_ngan_han_N if no_ngan_han_N != 0 else 0
        thanh_toan_hien_hanh_N_1 = tsnh_n_1 / no_ngan_han_N_1 if no_ngan_han_N_1 != 0 else 0
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric(label="Chá»‰ sá»‘ Thanh toÃ¡n Hiá»‡n hÃ nh (NÄƒm trÆ°á»›c)", value=f"{thanh_toan_hien_hanh_N_1:.2f} láº§n")
        with col2:
            st.metric(label="Chá»‰ sá»‘ Thanh toÃ¡n Hiá»‡n hÃ nh (NÄƒm sau)", value=f"{thanh_toan_hien_hanh_N:.2f} láº§n", delta=f"{thanh_toan_hien_hanh_N - thanh_toan_hien_hanh_N_1:.2f}")
            
    except IndexError:
        st.warning("Thiáº¿u chá»‰ tiÃªu 'TÃ€I Sáº¢N NGáº®N Háº N' hoáº·c 'Ná»¢ NGáº®N Háº N' Ä‘á»ƒ tÃ­nh chá»‰ sá»‘.")
        thanh_toan_hien_hanh_N = "N/A"
        thanh_toan_hien_hanh_N_1 = "N/A"
    except ZeroDivisionError:
        st.warning("Ná»£ ngáº¯n háº¡n báº±ng 0, khÃ´ng thá»ƒ tÃ­nh chá»‰ sá»‘ thanh toÃ¡n hiá»‡n hÃ nh.")
        thanh_toan_hien_hanh_N = "N/A"
        thanh_toan_hien_hanh_N_1 = "N/A"

    st.divider()

    # --- Láº¥y API Key ---
    api_key = st.secrets.get("GEMINI_API_KEY")
    if not api_key:
        st.error("Lá»—i: KhÃ´ng tÃ¬m tháº¥y KhÃ³a API. Vui lÃ²ng cáº¥u hÃ¬nh KhÃ³a 'GEMINI_API_KEY' trong Streamlit Secrets.")
    else:
        # Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘á»ƒ gá»­i cho AI
        data_for_ai_markdown = df_processed.to_markdown(index=False)
        st.session_state.data_for_ai = data_for_ai_markdown
        
        # --- Chá»©c nÄƒng 5: Nháº­n xÃ©t AI ban Ä‘áº§u ---
        st.subheader("5. Nháº­n xÃ©t Tá»•ng quan tá»« AI")
        if st.button("Táº¡o nháº­n xÃ©t tá»•ng quan"):
            prompt_initial = f"""
            Báº¡n lÃ  má»™t chuyÃªn gia phÃ¢n tÃ­ch tÃ i chÃ­nh chuyÃªn nghiá»‡p. Dá»±a trÃªn báº£ng dá»¯ liá»‡u sau Ä‘Ã¢y, hÃ£y Ä‘Æ°a ra má»™t nháº­n xÃ©t khÃ¡ch quan, ngáº¯n gá»n (3-4 Ä‘oáº¡n) vá» tÃ¬nh hÃ¬nh tÃ i chÃ­nh cá»§a doanh nghiá»‡p. 
            PhÃ¢n tÃ­ch cá»§a báº¡n cáº§n táº­p trung vÃ o cÃ¡c Ä‘iá»ƒm chÃ­nh sau:
            1. Tá»‘c Ä‘á»™ tÄƒng trÆ°á»Ÿng cá»§a cÃ¡c chá»‰ tiÃªu quan trá»ng (TÃ i sáº£n, Nguá»“n vá»‘n, Doanh thu, Lá»£i nhuáº­n náº¿u cÃ³).
            2. Sá»± thay Ä‘á»•i trong cÆ¡ cáº¥u tÃ i sáº£n vÃ  nguá»“n vá»‘n (Tá»· trá»ng).
            3. ÄÃ¡nh giÃ¡ sÆ¡ bá»™ vá» kháº£ nÄƒng thanh toÃ¡n hiá»‡n hÃ nh.
            
            Dá»¯ liá»‡u phÃ¢n tÃ­ch:
            {st.session_state.data_for_ai}
            """
            with st.spinner('Gemini Ä‘ang phÃ¢n tÃ­ch...'):
                ai_result = get_gemini_response(api_key, prompt_initial)
                st.info(ai_result)
                st.session_state.initial_analysis = ai_result
        
        st.divider()

        # --- Chá»©c nÄƒng 6: Khung Chat tÆ°Æ¡ng tÃ¡c ---
        st.subheader("6. TrÃ² chuyá»‡n vá»›i AI vá» dá»¯ liá»‡u")

        # Khá»Ÿi táº¡o lá»‹ch sá»­ chat
        if "messages" not in st.session_state:
            # Báº¯t Ä‘áº§u vá»›i má»™t tin nháº¯n chÃ o má»«ng tá»« AI
            st.session_state.messages = [{
                "role": "assistant", 
                "content": "TÃ´i Ä‘Ã£ sáºµn sÃ ng. Báº¡n muá»‘n há»i gÃ¬ vá» bÃ¡o cÃ¡o tÃ i chÃ­nh nÃ y?"
            }]

        # Hiá»ƒn thá»‹ cÃ¡c tin nháº¯n Ä‘Ã£ cÃ³
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        # Láº¥y input tá»« ngÆ°á»i dÃ¹ng
        if user_prompt := st.chat_input("Äáº·t cÃ¢u há»i cá»§a báº¡n á»Ÿ Ä‘Ã¢y..."):
            # ThÃªm tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng vÃ o lá»‹ch sá»­ vÃ  hiá»ƒn thá»‹
            st.session_state.messages.append({"role": "user", "content": user_prompt})
            with st.chat_message("user"):
                st.markdown(user_prompt)

            # Táº¡o prompt hoÃ n chá»‰nh cho AI
            # GhÃ©p ná»‘i bá»‘i cáº£nh dá»¯ liá»‡u, phÃ¢n tÃ­ch ban Ä‘áº§u (náº¿u cÃ³) vÃ  cÃ¢u há»i má»›i
            context_prompt = f"""
            Bá»‘i cáº£nh: Báº¡n lÃ  má»™t chuyÃªn gia tÃ i chÃ­nh Ä‘ang trÃ² chuyá»‡n vá»›i ngÆ°á»i dÃ¹ng vá» báº£ng dá»¯ liá»‡u sau:
            {st.session_state.data_for_ai}
            
            {"PhÃ¢n tÃ­ch tá»•ng quan ban Ä‘áº§u cá»§a báº¡n lÃ : " + st.session_state.initial_analysis if 'initial_analysis' in st.session_state else ""}

            HÃ£y dá»±a vÃ o bá»‘i cáº£nh trÃªn Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng má»™t cÃ¡ch ngáº¯n gá»n, chÃ­nh xÃ¡c.
            """
            
            # Chuáº©n bá»‹ lá»‹ch sá»­ chat cho API
            chat_history_for_api = []
            for msg in st.session_state.messages:
                chat_history_for_api.append({
                    "role": "model" if msg["role"] == "assistant" else msg["role"],
                    "parts": [msg["content"]]
                })

            # Láº¥y vÃ  hiá»ƒn thá»‹ pháº£n há»“i cá»§a AI
            with st.chat_message("assistant"):
                with st.spinner("AI Ä‘ang suy nghÄ©..."):
                    full_prompt = context_prompt + "\n\nCÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng: " + user_prompt
                    response = get_gemini_response(api_key, user_prompt, is_chat=True, chat_history=chat_history_for_api[:-1])
                    st.markdown(response)
            
            # ThÃªm pháº£n há»“i cá»§a AI vÃ o lá»‹ch sá»­
            st.session_state.messages.append({"role": "assistant", "content": response})

else:
    st.info("ChÃ o má»«ng báº¡n Ä‘áº¿n vá»›i á»©ng dá»¥ng PhÃ¢n tÃ­ch BÃ¡o cÃ¡o TÃ i chÃ­nh. Vui lÃ²ng táº£i lÃªn file Excel Ä‘á»ƒ báº¯t Ä‘áº§u.")
